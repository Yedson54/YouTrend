{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72d3fd03",
   "metadata": {},
   "source": [
    "# Duration Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "25516ee5-abb5-4c8b-a312-15cbe9635452",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from typing import List, Literal\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, Series, Timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfefbba1",
   "metadata": {},
   "source": [
    "* all dataframe should have :\n",
    "  * `scanTimeStamp` column: a timestamp designing the collection time (in absolute second)\n",
    "  * Keep a consistent naming style for collected data files. I suggest : `dataset_scan_{date}_{hour}_{min}`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c94ad5",
   "metadata": {},
   "source": [
    "Here is an enhanced version of the text:\n",
    "\n",
    "- **Objective (alternative 1)**: Predict the probability that a video **_leaves_** the YouTube Trending list, given its characteristics.\n",
    "- [x] **Objective (alternative 2)**: Predict the probability that a video **_enters_** the YouTube Trending list, given its characteristics. And given that it is trending, predict its rank.\n",
    "\n",
    "- **Output**\n",
    "  - Probabilities to enter in trend given some characteristics, at current date/time\n",
    "  - Display survival curves by Dayof Week / by videoCategory / by videoLength cat (0-5 min, 5min-10min, 10min - 25min, 25min+)\n",
    "\n",
    "- **Features**: \n",
    "  - **videoID**: a unique identifier of the video\n",
    "  - **scanDateTime**: the date and time of collecting the sample. It identifies a group of videos collected together at a given time, i.e., the set of videos in YouTube Trending at the moment of the scan.\n",
    "  - **videoPublishDate**: the date and time when the video was published\n",
    "  - **Trend date**: the date and time when the video entered the YouTube Trending list\n",
    "  - **creatorSubscriberNumber**: the number of subscribers of the video creator\n",
    "  - **videoTrendsRanking**: the video's ranking in the YouTube Trending list\n",
    "  - **videoLengthSeconds**: the video's length in seconds\n",
    "  - **videoType**: the video's type (now, recently trending, short)\n",
    "  - **videoCategory**: the video's category\n",
    "  - **exactViewNumber**: the number of views of the video\n",
    "  - **numberLikes**: the number of likes of the video\n",
    "  - **numberOfComments**: the number of comments on the video\n",
    "  - **isCreatorVerified**: a binary indicator of whether the video creator is verified or not\n",
    "  - **videoKeywords**: the keywords associated with the video\n",
    "\n",
    "\n",
    "**Preprocessing**\n",
    "* Load the data\n",
    "* Wrangle the data (extract relevant information from each column and convert to the appropriate type)\n",
    "* (alternative 1) Create a binary indicator of the presence of the video in the YouTube Trending list. By default, all videos observed in the sample have value \"1\" (because we are collecting only trending videos). Then, the first time the video disappears from the dataset, we create a row for this video with the value \"0\" for the indicator variable.\n",
    "* [x] (alternative 2) Create a binary indicator of the presence of the video in the YouTube Trending list. Here, it is simpler. Comparing the publish date with the trend date gives us the duration before entering the trend. We define observation periods on which videos whose trend date have not yet been reached get value \"0\" for the indicator variable. The indicator variable is \"1\" only for the trend date and after. We can delete all the observations of the video after the first entry in the trend (after its trend date).  \n",
    "  * **start date** : most ancient publish date\n",
    "  * **end date**: one day/hour before the most recent scraping date ()\n",
    "  * **Assumption 1**: first obervation scraping date = first observation trend date\n",
    "  * **Assumption 2**: we observe the video from its publish date until the end date\n",
    "  * **duration** = first observation scraping date - self publish date\n",
    "  * **isTrend** = 1 if the video has been observed between [min(publishDate), end date]\n",
    "\n",
    "**Modeling**\n",
    "* Train a model to predict the variable \"isTrend\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a130c045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 15)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>scanTimestamp</th>\n",
       "      <th>videoExactPublishDate</th>\n",
       "      <th>creatorSubscriberNumber</th>\n",
       "      <th>videoTrendsRanking</th>\n",
       "      <th>videoLengthSeconds</th>\n",
       "      <th>videoType</th>\n",
       "      <th>videoCategory</th>\n",
       "      <th>trendingCountry</th>\n",
       "      <th>exactViewNumber</th>\n",
       "      <th>numberLikes</th>\n",
       "      <th>numberOfComments</th>\n",
       "      <th>isCreatorVerified</th>\n",
       "      <th>videoKeywords</th>\n",
       "      <th>Epoch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfmUsDJjBkU</td>\n",
       "      <td>1.702948e+09</td>\n",
       "      <td>2023-12-17T02:02:00-08:00</td>\n",
       "      <td>5.79M subscribers</td>\n",
       "      <td>0</td>\n",
       "      <td>4585</td>\n",
       "      <td>Now</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>FR</td>\n",
       "      <td>2,489,981 views</td>\n",
       "      <td>183K</td>\n",
       "      <td>3.1K</td>\n",
       "      <td>True</td>\n",
       "      <td>['Mastu', 'Mastus', 'Humour', 'Matsu', 'loat',...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9gAADPMt1FU</td>\n",
       "      <td>1.702948e+09</td>\n",
       "      <td>2023-12-17T10:28:05-08:00</td>\n",
       "      <td>724K subscribers</td>\n",
       "      <td>1</td>\n",
       "      <td>1056</td>\n",
       "      <td>Now</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>FR</td>\n",
       "      <td>325,905 views</td>\n",
       "      <td>57K</td>\n",
       "      <td>1.2K</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LnW-DwBrWLk</td>\n",
       "      <td>1.702948e+09</td>\n",
       "      <td>2023-12-17T07:59:59-08:00</td>\n",
       "      <td>4M subscribers</td>\n",
       "      <td>0</td>\n",
       "      <td>827</td>\n",
       "      <td>Now</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>FR</td>\n",
       "      <td>492,696 views</td>\n",
       "      <td>39K</td>\n",
       "      <td>563</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K4GQRiuNpP0</td>\n",
       "      <td>1.702948e+09</td>\n",
       "      <td>2023-12-17T08:00:33-08:00</td>\n",
       "      <td>1.99M subscribers</td>\n",
       "      <td>1</td>\n",
       "      <td>2773</td>\n",
       "      <td>Now</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>FR</td>\n",
       "      <td>301,552 views</td>\n",
       "      <td>12K</td>\n",
       "      <td>438</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aZOiDNzoeWQ</td>\n",
       "      <td>1.702948e+09</td>\n",
       "      <td>2023-12-17T02:17:24-08:00</td>\n",
       "      <td>9.19M subscribers</td>\n",
       "      <td>2</td>\n",
       "      <td>1679</td>\n",
       "      <td>Now</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>FR</td>\n",
       "      <td>979,201 views</td>\n",
       "      <td>63K</td>\n",
       "      <td>1.7K</td>\n",
       "      <td>True</td>\n",
       "      <td>['michou', 'roue', 'tournes', 'souffres', 'vid...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       videoId  scanTimestamp      videoExactPublishDate  \\\n",
       "0  bfmUsDJjBkU   1.702948e+09  2023-12-17T02:02:00-08:00   \n",
       "1  9gAADPMt1FU   1.702948e+09  2023-12-17T10:28:05-08:00   \n",
       "2  LnW-DwBrWLk   1.702948e+09  2023-12-17T07:59:59-08:00   \n",
       "3  K4GQRiuNpP0   1.702948e+09  2023-12-17T08:00:33-08:00   \n",
       "4  aZOiDNzoeWQ   1.702948e+09  2023-12-17T02:17:24-08:00   \n",
       "\n",
       "  creatorSubscriberNumber  videoTrendsRanking  videoLengthSeconds videoType  \\\n",
       "0       5.79M subscribers                   0                4585       Now   \n",
       "1        724K subscribers                   1                1056       Now   \n",
       "2          4M subscribers                   0                 827       Now   \n",
       "3       1.99M subscribers                   1                2773       Now   \n",
       "4       9.19M subscribers                   2                1679       Now   \n",
       "\n",
       "   videoCategory trendingCountry  exactViewNumber numberLikes  \\\n",
       "0         Comedy              FR  2,489,981 views        183K   \n",
       "1         Comedy              FR    325,905 views         57K   \n",
       "2         Comedy              FR    492,696 views         39K   \n",
       "3  Howto & Style              FR    301,552 views         12K   \n",
       "4  Entertainment              FR    979,201 views         63K   \n",
       "\n",
       "  numberOfComments  isCreatorVerified  \\\n",
       "0             3.1K               True   \n",
       "1             1.2K               True   \n",
       "2              563               True   \n",
       "3              438              False   \n",
       "4             1.7K               True   \n",
       "\n",
       "                                       videoKeywords  Epoch  \n",
       "0  ['Mastu', 'Mastus', 'Humour', 'Matsu', 'loat',...      1  \n",
       "1                                                NaN      1  \n",
       "2                                                NaN      1  \n",
       "3                                                NaN      1  \n",
       "4  ['michou', 'roue', 'tournes', 'souffres', 'vid...      1  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duration_df = pd.read_csv(\"../data/Poling_dataset.csv\").drop(columns=[\"Unnamed: 0\", \"Unnamed: 0.1\"])\n",
    "print(duration_df.shape)\n",
    "duration_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "519e311c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(785, 15) Index(['videoId', 'videoExactPublishDate', 'creatorSubscriberNumber',\n",
      "       'videoTrendsRanking', 'videoLengthSeconds', 'videoType',\n",
      "       'videoCategory', 'trendingCountry', 'exactViewNumber', 'numberLikes',\n",
      "       'numberOfComments', 'isCreatorVerified', 'videoKeywords',\n",
      "       'scanTimeStamp', 'Epoch'],\n",
      "      dtype='object')\n",
      "           views     result\n",
      "0  300,000 views   300000.0\n",
      "1  400.75K views   400750.0\n",
      "2     2.5M views  2500000.0\n",
      "3       NoSuffix        NaN\n",
      "(785, 18) 0.9974522292993631\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>videoId</th>\n",
       "      <th>videoExactPublishDate</th>\n",
       "      <th>creatorSubscriberNumber</th>\n",
       "      <th>videoTrendsRanking</th>\n",
       "      <th>videoLengthSeconds</th>\n",
       "      <th>videoType</th>\n",
       "      <th>videoCategory</th>\n",
       "      <th>trendingCountry</th>\n",
       "      <th>exactViewNumber</th>\n",
       "      <th>numberLikes</th>\n",
       "      <th>numberOfComments</th>\n",
       "      <th>isCreatorVerified</th>\n",
       "      <th>videoKeywords</th>\n",
       "      <th>scanTimeStamp</th>\n",
       "      <th>Epoch</th>\n",
       "      <th>firstTrendingTime</th>\n",
       "      <th>timeToTrendSeconds</th>\n",
       "      <th>isTrend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bfmUsDJjBkU</td>\n",
       "      <td>2023-12-17 10:02:00+00:00</td>\n",
       "      <td>5790000</td>\n",
       "      <td>0</td>\n",
       "      <td>4585</td>\n",
       "      <td>Now</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>FR</td>\n",
       "      <td>2489981</td>\n",
       "      <td>183000.0</td>\n",
       "      <td>3100.0</td>\n",
       "      <td>True</td>\n",
       "      <td>['Mastu', 'Mastus', 'Humour', 'Matsu', 'loat',...</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>140515.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9gAADPMt1FU</td>\n",
       "      <td>2023-12-17 18:28:05+00:00</td>\n",
       "      <td>724000</td>\n",
       "      <td>1</td>\n",
       "      <td>1056</td>\n",
       "      <td>Now</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>FR</td>\n",
       "      <td>325905</td>\n",
       "      <td>57000.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>110150.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LnW-DwBrWLk</td>\n",
       "      <td>2023-12-17 15:59:59+00:00</td>\n",
       "      <td>4000000</td>\n",
       "      <td>0</td>\n",
       "      <td>827</td>\n",
       "      <td>Now</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>FR</td>\n",
       "      <td>492696</td>\n",
       "      <td>39000.0</td>\n",
       "      <td>563.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>119036.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K4GQRiuNpP0</td>\n",
       "      <td>2023-12-17 16:00:33+00:00</td>\n",
       "      <td>1990000</td>\n",
       "      <td>1</td>\n",
       "      <td>2773</td>\n",
       "      <td>Now</td>\n",
       "      <td>Howto &amp; Style</td>\n",
       "      <td>FR</td>\n",
       "      <td>301552</td>\n",
       "      <td>12000.0</td>\n",
       "      <td>438.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>119002.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aZOiDNzoeWQ</td>\n",
       "      <td>2023-12-17 10:17:24+00:00</td>\n",
       "      <td>9190000</td>\n",
       "      <td>2</td>\n",
       "      <td>1679</td>\n",
       "      <td>Now</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>FR</td>\n",
       "      <td>979201</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>1700.0</td>\n",
       "      <td>True</td>\n",
       "      <td>['michou', 'roue', 'tournes', 'souffres', 'vid...</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>139591.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>780</th>\n",
       "      <td>_Q4pcR5H2OE</td>\n",
       "      <td>2023-12-16 09:30:17+00:00</td>\n",
       "      <td>290000</td>\n",
       "      <td>10</td>\n",
       "      <td>60</td>\n",
       "      <td>Short</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>FR</td>\n",
       "      <td>451293</td>\n",
       "      <td>73000.0</td>\n",
       "      <td>613.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 07:32:00.194941184+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>228818.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>iFDN9N-GIrw</td>\n",
       "      <td>2023-12-16 10:05:05+00:00</td>\n",
       "      <td>751000</td>\n",
       "      <td>11</td>\n",
       "      <td>60</td>\n",
       "      <td>Short</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>FR</td>\n",
       "      <td>684282</td>\n",
       "      <td>NaN</td>\n",
       "      <td>484.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 07:32:00.194941184+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>226730.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>782</th>\n",
       "      <td>9AYGP5imeWk</td>\n",
       "      <td>2023-12-16 15:02:32+00:00</td>\n",
       "      <td>321000</td>\n",
       "      <td>12</td>\n",
       "      <td>60</td>\n",
       "      <td>Short</td>\n",
       "      <td>Entertainment</td>\n",
       "      <td>FR</td>\n",
       "      <td>408654</td>\n",
       "      <td>23000.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 07:32:00.194941184+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>208883.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>783</th>\n",
       "      <td>IMsEt4YBF3Q</td>\n",
       "      <td>2023-12-16 17:20:20+00:00</td>\n",
       "      <td>22900</td>\n",
       "      <td>13</td>\n",
       "      <td>42</td>\n",
       "      <td>Short</td>\n",
       "      <td>Gaming</td>\n",
       "      <td>FR</td>\n",
       "      <td>258762</td>\n",
       "      <td>17000.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 07:32:00.194941184+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-19 01:03:55.763489024+00:00</td>\n",
       "      <td>200615.763489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>784</th>\n",
       "      <td>_6YR8xmqEFw</td>\n",
       "      <td>2023-12-17 12:30:10+00:00</td>\n",
       "      <td>78700</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>Short</td>\n",
       "      <td>Sports</td>\n",
       "      <td>FR</td>\n",
       "      <td>118273</td>\n",
       "      <td>5200.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2023-12-19 07:32:00.194941184+00:00</td>\n",
       "      <td>7</td>\n",
       "      <td>2023-12-19 06:27:16.206667520+00:00</td>\n",
       "      <td>151026.206668</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>785 rows × 18 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         videoId     videoExactPublishDate  creatorSubscriberNumber  \\\n",
       "0    bfmUsDJjBkU 2023-12-17 10:02:00+00:00                  5790000   \n",
       "1    9gAADPMt1FU 2023-12-17 18:28:05+00:00                   724000   \n",
       "2    LnW-DwBrWLk 2023-12-17 15:59:59+00:00                  4000000   \n",
       "3    K4GQRiuNpP0 2023-12-17 16:00:33+00:00                  1990000   \n",
       "4    aZOiDNzoeWQ 2023-12-17 10:17:24+00:00                  9190000   \n",
       "..           ...                       ...                      ...   \n",
       "780  _Q4pcR5H2OE 2023-12-16 09:30:17+00:00                   290000   \n",
       "781  iFDN9N-GIrw 2023-12-16 10:05:05+00:00                   751000   \n",
       "782  9AYGP5imeWk 2023-12-16 15:02:32+00:00                   321000   \n",
       "783  IMsEt4YBF3Q 2023-12-16 17:20:20+00:00                    22900   \n",
       "784  _6YR8xmqEFw 2023-12-17 12:30:10+00:00                    78700   \n",
       "\n",
       "     videoTrendsRanking  videoLengthSeconds videoType  videoCategory  \\\n",
       "0                     0                4585       Now         Comedy   \n",
       "1                     1                1056       Now         Comedy   \n",
       "2                     0                 827       Now         Comedy   \n",
       "3                     1                2773       Now  Howto & Style   \n",
       "4                     2                1679       Now  Entertainment   \n",
       "..                  ...                 ...       ...            ...   \n",
       "780                  10                  60     Short  Entertainment   \n",
       "781                  11                  60     Short  Entertainment   \n",
       "782                  12                  60     Short  Entertainment   \n",
       "783                  13                  42     Short         Gaming   \n",
       "784                  14                  48     Short         Sports   \n",
       "\n",
       "    trendingCountry  exactViewNumber  numberLikes  numberOfComments  \\\n",
       "0                FR          2489981     183000.0            3100.0   \n",
       "1                FR           325905      57000.0            1200.0   \n",
       "2                FR           492696      39000.0             563.0   \n",
       "3                FR           301552      12000.0             438.0   \n",
       "4                FR           979201      63000.0            1700.0   \n",
       "..              ...              ...          ...               ...   \n",
       "780              FR           451293      73000.0             613.0   \n",
       "781              FR           684282          NaN             484.0   \n",
       "782              FR           408654      23000.0              37.0   \n",
       "783              FR           258762      17000.0              33.0   \n",
       "784              FR           118273       5200.0              24.0   \n",
       "\n",
       "     isCreatorVerified                                      videoKeywords  \\\n",
       "0                 True  ['Mastu', 'Mastus', 'Humour', 'Matsu', 'loat',...   \n",
       "1                 True                                                NaN   \n",
       "2                 True                                                NaN   \n",
       "3                False                                                NaN   \n",
       "4                 True  ['michou', 'roue', 'tournes', 'souffres', 'vid...   \n",
       "..                 ...                                                ...   \n",
       "780               True                                                NaN   \n",
       "781               True                                                NaN   \n",
       "782               True                                                NaN   \n",
       "783              False                                                NaN   \n",
       "784              False                                                NaN   \n",
       "\n",
       "                          scanTimeStamp  Epoch  \\\n",
       "0   2023-12-19 01:03:55.763489024+00:00      1   \n",
       "1   2023-12-19 01:03:55.763489024+00:00      1   \n",
       "2   2023-12-19 01:03:55.763489024+00:00      1   \n",
       "3   2023-12-19 01:03:55.763489024+00:00      1   \n",
       "4   2023-12-19 01:03:55.763489024+00:00      1   \n",
       "..                                  ...    ...   \n",
       "780 2023-12-19 07:32:00.194941184+00:00      7   \n",
       "781 2023-12-19 07:32:00.194941184+00:00      7   \n",
       "782 2023-12-19 07:32:00.194941184+00:00      7   \n",
       "783 2023-12-19 07:32:00.194941184+00:00      7   \n",
       "784 2023-12-19 07:32:00.194941184+00:00      7   \n",
       "\n",
       "                      firstTrendingTime  timeToTrendSeconds  isTrend  \n",
       "0   2023-12-19 01:03:55.763489024+00:00       140515.763489     True  \n",
       "1   2023-12-19 01:03:55.763489024+00:00       110150.763489     True  \n",
       "2   2023-12-19 01:03:55.763489024+00:00       119036.763489     True  \n",
       "3   2023-12-19 01:03:55.763489024+00:00       119002.763489     True  \n",
       "4   2023-12-19 01:03:55.763489024+00:00       139591.763489     True  \n",
       "..                                  ...                 ...      ...  \n",
       "780 2023-12-19 01:03:55.763489024+00:00       228818.763489     True  \n",
       "781 2023-12-19 01:03:55.763489024+00:00       226730.763489     True  \n",
       "782 2023-12-19 01:03:55.763489024+00:00       208883.763489     True  \n",
       "783 2023-12-19 01:03:55.763489024+00:00       200615.763489     True  \n",
       "784 2023-12-19 06:27:16.206667520+00:00       151026.206668    False  \n",
       "\n",
       "[785 rows x 18 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_data(\n",
    "        folder: str = None,\n",
    "        pattern: str = \"dataset*\",\n",
    "        use_filenames: bool = False,\n",
    "        filenames: List[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Load data from a folder or specific files.\n",
    "\n",
    "    Args:\n",
    "        folder (str, optional): The path to the folder containing the data files.\n",
    "        pattern (str, optional): The pattern to match files in the folder.\n",
    "        use_filenames (bool, optional): If True, use the filenames provided in the \n",
    "            'filenames' parameter. If False, load all files in the folder.\n",
    "        filenames (List[str], optional): A list of filenames to load. Only used if \n",
    "            'use_filenames' is True.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the loaded data.\n",
    "    \"\"\"\n",
    "    if use_filenames:\n",
    "        files = filenames\n",
    "    else:\n",
    "        files = glob.glob(rf\"{folder}/{pattern}\")\n",
    "\n",
    "    dfs = [pd.read_csv(file, index_col=0) for file in files]\n",
    "    concat_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "    return concat_df\n",
    "\n",
    "\n",
    "def _parse_numeric_column(series: Series) -> Series:\n",
    "    \"\"\"\n",
    "    Parse a numeric column, handling 'K' and 'M' suffixes.\n",
    "\n",
    "    Args:\n",
    "        series (Series): The series to parse.\n",
    "\n",
    "    Returns:\n",
    "        Series: The parsed series, with 'K' and 'M' suffixes converted to numeric values.\n",
    "    \"\"\"\n",
    "    # Normalize columns (remove whitespace, lowercase, remove \",\")\n",
    "    series = series.str.strip().str.lower().replace(',', '', regex=True)\n",
    "\n",
    "    # Define a regex pattern to match numbers with optional K or M suffix\n",
    "    pattern = r'(\\d+(?:\\.\\d+)?)([KkMm])?'  # regex group capture\n",
    "\n",
    "    # Extract the numeric part and the suffix.\n",
    "    result_df = series.str.extract(pattern, expand=True)\n",
    "    numeric_part = pd.to_numeric(result_df[0], errors='coerce')\n",
    "    suffix_series = result_df[1]\n",
    "\n",
    "    # Define a dictionary to map suffixes to multiplication factors\n",
    "    suffix_multiplier = {'K': 1e3, 'k': 1e3, 'M': 1e6, 'm': 1e6}\n",
    "\n",
    "    # Multiply by the corresponding factor based on the suffix\n",
    "    multiplier = suffix_series.map(suffix_multiplier)\n",
    "\n",
    "    # Replace NaN values with 1 (default multiplier for rows without a suffix)\n",
    "    multiplier = multiplier.fillna(1)\n",
    "\n",
    "    # Multiply the numeric part by the multiplier, ensure numeric type.\n",
    "    result_series = numeric_part * multiplier\n",
    "    result_series = pd.to_numeric(result_series, downcast='integer')\n",
    "\n",
    "    return result_series\n",
    "\n",
    "\n",
    "def clean_columns(data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Clean columns in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame to clean.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The cleaned DataFrame.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "\n",
    "    # Datetime columns\n",
    "    df[\"videoExactPublishDate\"] = pd.to_datetime(df[\"videoExactPublishDate\"], utc=True)\n",
    "    df[\"scanTimeStamp\"] = pd.to_datetime(df[\"scanTimeStamp\"], unit=\"s\", utc=True)\n",
    "\n",
    "    # Numeric columns\n",
    "    df[\"numberLikes\"] = _parse_numeric_column(df[\"numberLikes\"])\n",
    "    df[\"exactViewNumber\"] = _parse_numeric_column(df[\"exactViewNumber\"])\n",
    "    df[\"numberOfComments\"] = _parse_numeric_column(df[\"numberOfComments\"])\n",
    "    df[\"creatorSubscriberNumber\"] = _parse_numeric_column(df[\"creatorSubscriberNumber\"])\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_duration_model_columns(data: DataFrame, frequency: Literal[\"hour\", \"day\"] = \"hour\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Adjust the end date of the data based on the chosen frequency and compute\n",
    "    the duration before trending for each video.\n",
    "\n",
    "    Args:\n",
    "        data (DataFrame): The DataFrame containing the data.\n",
    "        frequency (Literal[\"hour\", \"day\"]): The frequency for the adjustment. \n",
    "            If \"hour\", subtract 1 hour from the end date. \n",
    "            If \"day\", subtract 1 day from the end date.\n",
    "            Other possible values: see `pandas.Timedelta()`.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The DataFrame with the time to trend in seconds.\n",
    "    \"\"\"\n",
    "    df = data.copy()\n",
    "    start_date = pd.to_datetime(df[\"videoExactPublishDate\"].min())\n",
    "    end_date = pd.to_datetime(df[\"scanTimeStamp\"].max())\n",
    "    end_date -= Timedelta(value=1.5, unit=frequency)\n",
    "\n",
    "    # Compute the time spent before entering in the trending list.\n",
    "    first_trending_time = df.groupby(\"videoId\")[\"scanTimeStamp\"].min()\n",
    "    first_trending_time.name = \"firstTrendingTime\"\n",
    "    df = df.merge(first_trending_time, left_on=\"videoId\", right_index=True)\n",
    "    df[\"timeToTrendSeconds\"] = (df[\"firstTrendingTime\"] - df[\"videoExactPublishDate\"]).dt.total_seconds()\n",
    "\n",
    "    # Determine whether or not the video has been trending\n",
    "    df[\"isTrend\"] = np.logical_and(df[\"firstTrendingTime\"] >= start_date, df[\"firstTrendingTime\"] <= end_date)\n",
    "\n",
    "    return df.sort_index()\n",
    "\n",
    "\n",
    "def processing_for_duration_model(\n",
    "        folder: str = None,\n",
    "        pattern: str = \"dataset*\",\n",
    "        use_filenames: bool = False,\n",
    "        filenames: List[str] = None,\n",
    "        frequency: Literal[\"hour\", \"day\"] = \"hour\") -> DataFrame:\n",
    "    \"\"\"\n",
    "    Perform data processing operations for a duration model.\n",
    "\n",
    "    This function combines loading data, cleaning columns, and creating\n",
    "    duration model columns using the previously defined functions.\n",
    "\n",
    "    Args:\n",
    "        folder (str, optional): The path to the folder containing the data files.\n",
    "        pattern (str, optional): The pattern to match files in the folder.\n",
    "        use_filenames (bool, optional): If True, use the filenames provided in the \n",
    "            'filenames' parameter. If False, load all files in the folder.\n",
    "        filenames (List[str], optional): A list of filenames to load. Only used if \n",
    "            'use_filenames' is True.\n",
    "        frequency (Literal[\"hour\", \"day\"], optional): The frequency for the adjustment. \n",
    "            If \"hour\", subtract 1 hour from the end date. \n",
    "            If \"day\", subtract 1 day from the end date.\n",
    "            Other possible values: see `pandas.Timedelta()`.\n",
    "\n",
    "    Returns:\n",
    "        DataFrame: The processed DataFrame for the duration model.\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    data = load_data(\n",
    "        folder=folder, \n",
    "        pattern=pattern, \n",
    "        use_filenames=use_filenames, \n",
    "        filenames=filenames\n",
    "    )\n",
    "\n",
    "    # Clean columns\n",
    "    cleaned_data = clean_columns(data)\n",
    "\n",
    "    # Create duration model columns\n",
    "    processed_data = create_duration_model_columns(cleaned_data, frequency)\n",
    "\n",
    "    return processed_data\n",
    "\n",
    "\n",
    "# Usage\n",
    "# 1\n",
    "df = load_data(\"../data\")\n",
    "print(df.shape, df.columns)\n",
    "\n",
    "test_data = {\n",
    "    'views': ['300,000 views', '400.75K views', '2.5M views', 'NoSuffix']\n",
    "}\n",
    "test_df = pd.DataFrame(test_data)\n",
    "test_df['result'] = _parse_numeric_column(test_df['views'])\n",
    "print(test_df)\n",
    "\n",
    "# 2\n",
    "df1 = clean_columns(df)\n",
    "df1.head()\n",
    "\n",
    "# 3\n",
    "df2 = create_duration_model_columns(df1)\n",
    "print(df2.shape, df2[\"isTrend\"].sum() / len(df2))\n",
    "df2.head()\n",
    "\n",
    "# 4 (ALL IN ONE)\n",
    "super_df = processing_for_duration_model(\"../data/\")\n",
    "super_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "959d1ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class duration_model():\n",
    "#     # instantiate model\n",
    "#     # train model (fit method)\n",
    "#     # prediction method\n",
    "#     # prediction proba method\n",
    "#     # survival curves (use the features and their categories as parameters)\n",
    "#     # save model method\n",
    "#     # load model method\n",
    "#     pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
